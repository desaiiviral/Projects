{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Fantasy Player Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to be able to rank fantasy players based on past statistics. We will use clustering algorithmns to be able to rank players into distinguishable tiers. Ideally, this model can be used weekly throughout the NFL season based on solely this seasons performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data importing and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'fantasy.txt' does not exist: b'fantasy.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cea6615d2bed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#importing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fantasy.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#replacing all NAs with 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'fantasy.txt' does not exist: b'fantasy.txt'"
     ]
    }
   ],
   "source": [
    "#importing data\n",
    "stats = pd.read_csv('fantasy.txt')\n",
    "\n",
    "#replacing all NAs with 0\n",
    "stats.fillna(value = 0, inplace = True)\n",
    "\n",
    "#filtering for players that only had greater than 0 points\n",
    "stats = stats[stats.FantPt >= 16]\n",
    "\n",
    "#first we will reorder the dataframe from highest to lowest points scored\n",
    "#normal leagues\n",
    "stats_norm = stats.sort_values('FantPt', ascending = False)\n",
    "\n",
    "#ppr leagues\n",
    "stats_ppr = stats.sort_values('PPR', ascending = False)\n",
    "\n",
    "#std predictors\n",
    "std_predictors = ['Player', 'G', 'GS', 'Cmp', 'Att', 'Yds', 'TD', 'Int', 'Att.1',\n",
    "                  'Yds.1', 'Y/A', 'TD.1', 'Tgt', 'Rec', 'Yds.2', 'Y/R',\n",
    "                  'TD.2', 'Fmb', 'FL', 'TD.3', '2PM', '2PP', 'FantPt']\n",
    "#ppr predictors \n",
    "ppr_predictors = ['Player', 'G', 'GS', 'Cmp', 'Att', 'Yds', 'TD', 'Int', 'Att.1',\n",
    "                  'Yds.1', 'Y/A', 'TD.1', 'Tgt', 'Rec', 'Yds.2', 'Y/R',\n",
    "                  'TD.2', 'Fmb', 'FL', 'TD.3', '2PM', '2PP','PPR']\n",
    "\n",
    "#all relevant predictors to use for std PCA\n",
    "df_std = stats.filter(items = std_predictors)\n",
    "\n",
    "#all relevant predictors to use for PPR PCA\n",
    "df_ppr = stats.filter(items = ppr_predictors)\n",
    "\n",
    "\n",
    "#storing index as player names for std\n",
    "df_std.set_index('Player', inplace = True)\n",
    "\n",
    "#storing index as player names for ppr\n",
    "df_ppr.set_index('Player', inplace = True)\n",
    "\n",
    "#STD standardizing data\n",
    "df_std = StandardScaler().fit_transform(df_std)\n",
    "\n",
    "#PPR standardizing data\n",
    "df_ppr = StandardScaler().fit_transform(df_ppr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principial Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#function that allows us to do PCA and returns its variance ratio and a graph\n",
    "#The parameters are:\n",
    "#x - which is the maximum number of components\n",
    "#data - the data in question that we are performing PCA\n",
    "#df_name - name that will be used as title for graph\n",
    "\n",
    "def pca_variance_check(x, data, df_name):\n",
    "    #empty list to store variance ratio\n",
    "    pca_variance_list = []\n",
    "\n",
    "    #for loop that serachs for best ratio\n",
    "\n",
    "    for i in range(2,x):\n",
    "        pca = PCA(i, random_state = 0)\n",
    "        components = pca.fit_transform(data)\n",
    "        pca_variance = sum(pca.explained_variance_ratio_)\n",
    "        pca_variance_list.append(pca_variance)\n",
    "\n",
    "    #plotting our variance\n",
    "    #changing style\n",
    "    sns.set_style('darkgrid')\n",
    "\n",
    "    #changing fig size\n",
    "    plt.figure(figsize = (12,8))\n",
    "\n",
    "    #plotting our variance\n",
    "    ax = sns.lineplot(range(2,x), pca_variance_list)\n",
    "\n",
    "    #plot labels\n",
    "    ax.set(xlabel = '# of Components', ylabel = 'Explained VAR Ratio', \n",
    "           title = df_name + ' Variance Ratio Calculation')\n",
    "    return(pca_variance_list)\n",
    "    \n",
    "std_var = pca_variance_check(12, df_std, 'Standard League')\n",
    "ppr_var = pca_variance_check(12, df_ppr, 'PPR League')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So luckily for us both graphs have VERY similar VAR ratio explained so what we will do is use a fixed number of components for each type of scoring. Since we can't tell much from these graphs we will instead calculate the difference between components. So, the difference between 4 to 5, 5 to 6, etc. (essentially the derivative at each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that calculates the difference between components and prints a graph\n",
    "#the parameters are:\n",
    "#data - list of VAR ratio\n",
    "#df_name - name that will be used as title for graph\n",
    "\n",
    "def component_diff(data, df_name):\n",
    "    #calculating difference\n",
    "    dy = np.diff(data)\n",
    "\n",
    "    #changing fig size\n",
    "    plt.figure(figsize = (12,8))\n",
    "\n",
    "    #plotting our variance\n",
    "    ax = sns.lineplot(range(3,12), dy)\n",
    "\n",
    "    #plot labels\n",
    "    ax.set(xlabel = '# of Components', ylabel = 'Explained VAR Ratio',\n",
    "           title = df_name + ' VAR(n + 1) - Var(n) Calculation')\n",
    "    return(dy)\n",
    "\n",
    "std_diff = component_diff(std_var, 'Standard League')\n",
    "ppr_diff = component_diff(ppr_var, 'PPR League')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is a sharp decrease as we move from 4 components to 5 components. This tells us that when we increase our number of principal components from 4 to 5 our explained variance ratio only increases slightly. So, to keep our model simplier we will use 4 components.\n",
    "\n",
    "So do PCA for STD vs PPR leagues,\n",
    "Give each data frame Player name as index and position.\n",
    "Then subset all the dataframe into each position and use GMM on said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that will gets us a df into 4 components using PCA\n",
    "#parameters are:\n",
    "#data - data to perform PCA on\n",
    "#index_names - name of index (player names in this case)\n",
    "#position_names - positions of players\n",
    "\n",
    "def pca_4(data, index_names, position_names):\n",
    "    #running PCA\n",
    "    pca = PCA(n_components = 4)\n",
    "\n",
    "    #getting our components\n",
    "    components = pca.fit_transform(data)\n",
    "\n",
    "    #getting our new dataframe\n",
    "    pca_df = pd.DataFrame(components, columns = ['PC 1', 'PC 2', 'PC 3', 'PC 4'])\n",
    "\n",
    "    #adding player names\n",
    "    pca_df['Player'] = index_names\n",
    "    \n",
    "    #adding positions\n",
    "    pca_df['Position'] = position_names\n",
    "\n",
    "    #converting player names to index values\n",
    "    pca_df.set_index('Player', inplace = True)\n",
    "\n",
    "    #checking our variance ratio\n",
    "    var_sum = sum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    return(pca_df, var_sum)\n",
    "\n",
    "a, b = pca_4(df_std, stats_norm.Player, stats_norm.FantPos)\n",
    "a2, b2 = pca_4(df_ppr, stats_ppr.Player, stats_norm.FantPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTER THESE PLAYERS BASED ON POSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering players based on position\n",
    "\n",
    "#poisitions list to parse through\n",
    "positions = ['QB', 'RB', 'WR', 'TE']\n",
    "\n",
    "#empty dict to store individual position data for normal leagues\n",
    "stats_norm_pos = {}\n",
    "stats_ppr_pos = {}\n",
    "\n",
    "#for loop that stores each position data into dict\n",
    "for position in positions:\n",
    "    stats_norm_pos[position] = a[a.Position == position]\n",
    "    stats_ppr_pos[position] = a2[a2.Position == position]\n",
    "\n",
    "#now we remove the position column for each position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first model we will be using Gaussian Mixture. Just like when we used PCA we need to find the right number of clusters. In order to do so we will look at silhouette scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "#list to hold silhouette scores\n",
    "silhouette_gmm = []\n",
    "\n",
    "#we will look from 4 to 10 clusters\n",
    "for j in range(2, 11):\n",
    "    gmm = GaussianMixture(n_components = j, random_state = 0).fit(a2)\n",
    "    #get labels\n",
    "    labels = gmm.predict(a2)\n",
    "    #insert score into list\n",
    "    silhouette_gmm.append(silhouette_score(a2, labels))\n",
    "\n",
    "#plotting our silhouette scores for readability.\n",
    "\n",
    "#changing fig size\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "#plotting our variance\n",
    "ax = sns.lineplot(range(2,11), silhouette_gmm)\n",
    "\n",
    "#plot labels\n",
    "ax.set(xlabel = '# of Clusters', ylabel = 'Silhouette Scores', \n",
    "       title = 'Cluster Silhouette Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main problems with finding identifiable clusters is that we simply do not care about the lower end really. The difference between a Tier 1 player and a Tier 2 player isn't the same as a Tier 2 player and a Tier 3 player. In general the furthur down you go the bigger the gap between players. So in order to prevent creating an enormous amount of tiers, we will look for something in the 2-10 range. Since our scores are relatively small, we will pick the highest score which is 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmm using 6 components\n",
    "gmm = GaussianMixture(n_components = 8, covariance_type = 'full', random_state = 0).fit(a)\n",
    "\n",
    "#labeling our points based on GMM\n",
    "labels = gmm.predict(a)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['Player'] = a.index.values\n",
    "results['Cluster Number'] = labels\n",
    "\n",
    "#This clustering type gives you the 7 different player types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
